{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">**Kaggle Test Using TensorFlow**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.13.1\n"
     ]
    }
   ],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import math as math\n",
    "# import sys\n",
    "# import tarfile\n",
    "# from IPython.display import display, Image\n",
    "# from scipy import ndimage\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from six.moves.urllib.request import urlretrieve\n",
    "# from six.moves import cPickle as pickle\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"TensorFlow Version:\",tf.__version__)\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.csv', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "path = os.listdir(\"../../data/digit-recognizer\")\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "train_data = pd.read_csv('../../data/digit-recognizer/train.csv')\n",
    "test_data = pd.read_csv(\"../../data/digit-recognizer/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the data\n",
    "y_train = train_data['label'].values\n",
    "X_train = train_data.drop(columns=['label']).values/255\n",
    "\n",
    "# Test Data\n",
    "X_test_public = test_data.values/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save_submission(name, dataset, pred_labels):\n",
    "    # Generating submission using pandas for grading\n",
    "    submission = pd.DataFrame({'ImageId': range(1, len(dataset) + 1), 'Label': pred_labels })\n",
    "    submission.to_csv(name, index = False)\n",
    "\n",
    "def displayImages(data, label):\n",
    "    fig, axes = plt.subplots(2,5, figsize=(12,5))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    xsize = data.shape[0]\n",
    "    # Get random Variables\n",
    "    idx = np.random.randint(0, xsize, size=10)\n",
    "    for i in range(10):\n",
    "        axes[i].imshow(data[idx[i],:].reshape(28,28), cmap='gray')\n",
    "        axes[i].axis('off') # hide the axes ticks\n",
    "        axes[i].set_title(str(int(label[idx[i]])), color= 'black', fontsize=25)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "displayImages(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (41580, 784) (41580,)\n",
      "Validation: (210, 784) (210,)\n",
      "Testing: (210, 784) (210,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAr8AAAFACAYAAAC1NRS/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xu8jXXe//HPF0kOEWWkuXPIOMSkpHLnnBGSJDFIpaOpxtxMpttMzWNvTbil2zSVGtPQ6CDVz6nDKITKuFXo4BBTkaQMUqm22Pj+/lhrj/35rrXXYa/Dtfb6vp6Px37Y77WutdaHLtf+dPlc38tYawUAAADwQaWgCwAAAACyheYXAAAA3qD5BQAAgDdofgEAAOANml8AAAB4g+YXAAAA3qD5BQAAgDdoflNgjLFJfC0Pul4ExxgzIsH95GdB14rcY4wZV3o/Cboe5A5jTC1jTKExZr0x5jtjzDfGmLeNMbcbY6oGXR9yA/uJViXoAiq4f8V5/jgRqRv+/u0M14KK4aiI7Inx/MFsFYKKwRjTQkQKgq4DuccY00hEVohI4/BDRSJyvIi0D39dZYzpYa39KpACkRPYTyJx5jcF1toGsb5EZGKpzWcEVSdyyo44+80bQReI3GGMqSShY0c1Efm/gMtBDjHGVBaRFyTU0HwhIj2ttTVEpLqIDBGRb0XkHBF5KqgaETz2k+hofjPrhvCvK621WwKtBEBFNEpEOkroB9PigGtBbhkhIj8Nfz/QWrtURMRae9Ra+4yIjAw/18cY0yOA+pAbRgj7SQSa3wwxxlwoIq3C8a9B1gKg4jHGNBGRCSLypYiMCbgc5J5rw78ut9ZG+1eBOSKyLfz9NdkpCTmI/SQKmt/MKTnru19EnguyEAAV0qMiUkNEfm2tjTUnDs8YY6pL6F8EREQWRdvGWmtF5OVwvDgbdSG3sJ+UjeY3A4wxNUVkcDjOttYWBVkPcsopxpi14attDxhjthpjnjTGdAu6MOQOY8xNItJDRJZaax8Puh7knFZy7Of3hhjblTzXwBhTN8Z2yE/sJ2Wg+c2MISJSM/w9Iw8orbqItBORQxL6+9dERK4SkeXGmJnGGFZg8Zwx5jQRmSIiB+TYPB5QWsNS3++MsV3p5xqWuRXyFftJGWh+M+PG8K/vWWvXBloJcsXnIjJeRNqKSDVrbV0JNcIdRWRpeJvrROSPwZSHHDJdRGqLSKG1dmvQxSAn1Sr1fax/WSz9XK0yt0K+Yj8pA81vmhljWovIBeHIWV+IiIi1drG1ttBa+7619mD4sSPW2lUi0ktEFoY3vdUY85PACkWgjDHDRaSviLwrIlMDLgcA8hLNb/qVnPX9QTxbNw/lY609KiJjw7GSiPQLsBwExBhTX0TuF5EjInKTtfZwwCUhd31b6vvqMbYr/dy3ZW6FfMV+Ugaa3zQK3yJweDjO9eluKUiNtfYjEdkbjk2DrAWBmSwi9UTkLyKy2RhTs/SXiPz7FqSlHvfutqQQkdAYVYnTYmxX+rnPy9wK+Yr9pAw0v+nVX0RODn/PyAOAZDQJ/3qLhM6+uF+/LbVtyWP3ZrNA5IwPJHSrdBGRNjG2K3lul7V2X2ZLQg5iPykDzW96lYw8fCQirwVZCCoWY8wZcux/nLbF2haA38LLZ/4jHHtH28YYYyR0PYEIdwf0EvtJ2Wh+08QYc7qI/CwcZ4YXjgZKDi7xnp8SjkdF5MWMF4WcY63tZq01ZX1JaLWQkm1LHh8dYMkI1qzwr92NMRdEeX6QHBuhYq1of7GfREHzmz7XS+jP87CI/C3YUpBjGhlj3jLGjDTGNC1pho0xlYwxHSR0550B4W2nW2u3BFYpgIpiloisFxEjInONMT1E/n1cGSShOwSKiCyy1r4aUI0IHvtJFIYTlKkzxlQSka0i0khEnrfW9g+4JOQQY0xj0aMMByU0r1lLRI4v9fhjInIzV/kjGmNMoYgUiITO/AZbDXJB+NiyXEQahx8qktBJmGrh/I6I9ODia7+xn0TizG96/ExCja8IF7oh0r9EZJSIzBaRTSKyX0TqiEixiGwWkZki0slaez2NL4BEWWs/EZGzRORuCd2i1krouLJWQssndvCpoUF07CeROPMLAAAAb3DmFwAAAN6g+QUAAIA3aH4BAADgDZpfAAAAeIPmFwAAAN6oks0PM8awtEQeydRao+wn+SWTa9Kyr+QXjilIBMcUJKqsfYUzvwAAAPAGzS8AAAC8QfMLAAAAb9D8AgAAwBs0vwAAAPAGzS8AAAC8QfMLAAAAb9D8AgAAwBs0vwAAAPAGzS8AAAC8QfMLAAAAb1QJugAAAADkjl69eqn88ssvR2wzYMAAlRcsWJDRmtKJM78AAADwBs0vAAAAvEHzCwAAAG/Q/AIAAMAbXPAGZMnNN9+sckFBgcpr165Vedu2bTGfFxH54osvVD569KjKxcXFKr/55psqHzx4MEbFAABE/mwREZk+fbrKhw8fVvnFF1/MaE2p4MwvAAAAvEHzCwAAAG/Q/AIAAMAbxlqbvQ8zJnsfhoyz1ppMvG++7CeVKun/t3z33XdVbtOmTTbLERGRt956S+UOHTpk/DMztZ+I5M++kgsefPBBld1F7tu1a6fyd999l/YafD6mtGzZMu42mzdvzkIluY9jSvIqV66scseOHVW+/fbbVe7WrZvKNWvWjPsZRUVFKo8YMULluXPnxn2PdCtrX+HMLwAAALxB8wsAAABv0PwCAADAG8z8ZoA7K+PmRHTt2jWp91ixYoXK3bt3T/ozk+XzfF4izjzzTJU3bNgQc/vJkyer7M737d+/P+I17hxm1apVY36Gu67vj3/8Y5UfeOABld055fLwfT6vdu3aEY899NBDKo8aNUrlr7/+OqM1RbNjxw6VTz31VJU7deqk8urVq9Neg0/HlCeeeELlyy+/PO5rJk6cqPKXX36Z1GfOmzdP5b179yb1+lzh+zElEe5M76BBg1R2jzmZ8PHHH6vcvHnzjH+mi5lfAAAAeI/mFwAAAN6g+QUAAIA3mPlNQGFhYcznCwoKslNIEozJ2EjUv/k0n1cec+bMUXnw4MEqb9myRWV3fvfAgQOZKayUE088UeVoc8Wp8n0+b8qUKRGPjRkzRuU//OEPKo8fPz6jNYmIPPzwwyqPHDlS5Y0bN6rsXkeQ7LxpIvLpmFKjRg2V3TW2W7VqpXK0n8XucdzdJt3PR9vGnTOeNGmSyu7artng+zGlfv36EY+5+9Ozzz6r8sknn5zUZ7h//x955JGIbbZu3aryrFmzVK5Tp47K7rUObu/0/fffJ1VjIpj5BQAAgPdofgEAAOANml8AAAB4o0rQBeSjZOf13DV9RZJfGzgbM4KIrW7duioPGDAg5vZTp05VORszvq5MzPhC69+/f9xt3DV0s6Fz584xn9+0aZPKmZjxzWePP/64yi1atFDZna1N5Pobdxt3nV53Hd94TjnllIjH3PWGf/e738V83l0/1l2fHKlzZ3yffPLJiG169OiR1Hu6M70LFixQ+e6771b58OHDcd9z+PDhKrt1utc6HHfccSr/13/9V9zPSBfO/AIAAMAbNL8AAADwBs0vAAAAvME6vzkg2jrC8dYOdmd8461FnAn5tCZnOlx33XUqz5gxQ+VvvvlGZXeOq7i4ODOFBcy3NTndNXvdmUmRyNnN5cuXq9yzZ8+01+Xun9OmTVPZXa/1kksuUdldpzYTKvIxpUuXLiqvWLFC5Xhr7O7ZsyfiPX//+9+r7M70ujO/6eBeqzBhwgSV3dnlSpX0OTR3VnzgwIEqp2MmON+PKe5s7PXXX6/ymWeeGfc93DVzd+/erfLFF1+ssrtmbzr06tVL5b///e8q79u3T+VoM+ipYp1fAAAAeI/mFwAAAN6g+QUAAIA3mPkNgLuGrzvvF407P9a9e/c0VlQ+FXk+L1XuvJ6IyK5du1R255duu+02laPdKz0f5ft8XvPmzVVetWqVyu76zyIi69atU9ldczfVNZ9r1aoV8djatWtVPuOMM1SePn26yrfeemtKNZRHRTqmuH+/3XnGdu3aqez+rB07dqzK0WZ+n3rqqVRKTIvq1aur7M4Eu+sZu7/Pd955R+Xzzjsv5Zry7ZjSsGFDlWfNmqXyRRddlPR7PvzwwyqPGjUq+cJS1KxZM5W3bNmiMjO/AAAAQBbQ/AIAAMAbNL8AAADwBs0vAAAAvFEl6AJ8lMgFbq5cuMANx/zmN7+JeMwd1j98+LDKvlzglu/q1Kmj8pw5c2I+H+2i4kWLFqmc6gVurjvvvDPisaZNm8asa/369WmtId+dfvrpKrsXuLkXxV5zzTUq58LFbIlwb37i1u0+714Ad+6556o8evToiM+4//77UymxwqlatarKTz75pMpdu3ZN+j0///xzld2b2ATh6NGjKufSjZw48wsAAABv0PwCAADAGzS/AAAA8AYzv1ng3tQiEcz45rYrr7wy7jYrV67MQiXItNatW6t87733qnzWWWfFfP1XX30V8djGjRtVLigoSKom9wYU7vxuvXr1kno/JK9Vq1Yqx7th1AcffJDJcgIzf/58lSdOnKjyPffco/K4ceMi3sO3md8///nPKic74+seP0RELr/8cpW3bt2afGFp5tbgXosQbV/IFs78AgAAwBs0vwAAAPAGzS8AAAC8wcxvBrgzvvHW9R0/fnzEYytWrEhjRUi3DRs2RDzWvn17lQ8dOqSyO8ftzgDu2rUrTdUhFTVq1FC5sLBQ5V69eiX1fieddFLEY+66nsly15CNN2+aiBtuuEFl9zi2Zs0ald3f18MPPxzxnp999lnKdeWqAQMGqOz+N1m3bl3MnK/cGeAJEyao7K6Hjvh27Nih8rBhwyK2yYUZX1eDBg1UduuuWbOmyr/4xS9Udmej04kzvwAAAPAGzS8AAAC8QfMLAAAAbzDzmwHJrtnJfG/FM3PmzIjHhg8frvLFF18cM7vrv77xxhsqz5o1S2V3lg6Z0bhxY5Xd2c58dc4556h89tlnqzxw4MCYr091jrmicddVdeeu582bl81ycsbmzZtVdv9c0jGf7hv3OoMtW7YEVEly3Jle95jicq+bySTO/AIAAMAbNL8AAADwBs0vAAAAvMHMbxq46/i662O63PVemfmteFauXBnx2KOPPqpyly5dVG7durXK7jqpl112mcp9+vRROZH7uX/66adlVIxEHTx4UOUDBw6oXL169Zivd2e53fWeRUS+/PJLld9+++2Y2eWuqXv06FGVjxw5EvGaeHOCbdq0ifmec+fOVdnd13xbp9pd19c1adKkLFWSW9zjXrw/Jx+0bdtW5Q4dOiT1+uLi4nSWA+HMLwAAADxC8wsAAABv0PwCAADAG8z8lkOyM77uTC8zvvnptttuU7lq1aoqu7OiJ5xwgsq9e/dW2V1v9ve//33EZ06dOlXlK6+8MqFaUbaPPvpI5c6dO6tcu3btmK/fuXOnyu7McLRt4mnWrJnK7jyuu3bqm2++GfEe7u/D1bVr15jPr1q1SmXf5xDjrV/bsmVLld31b/NVvPWPJ0yYkM1yckKdOnVUrlevXkCVZJd73MolnPkFAACAN2h+AQAA4A2aXwAAAHjDZPM+28aYCnlT78LCQpULCgpibu/O9Lrr+uYLa21GFnCsqPtJurlrQbozlyIiL7zwgsr9+/fPaE3lkan9RMSffcVd97ddu3Yq//DDDyoPHDgw4j1efvnl9BeWZhXpmLJ7926V3TnO2bNnq3z11Venu4Sc4K7/7M78rlu3TuXzzjsv5c+s6MeUmTNnqnzttdfG3N5d13vhwoUR2yxdujT1wtJs/fr1Kp955pkqFxUVqTxkyBCVX3rppZRrKGtf4cwvAAAAvEHzCwAAAG/Q/AIAAMAbNL8AAADwBje5SEC8xd9d48ePz1AlyGfuTTDGjBkTUCUIWuvWrVWOt1j8n//8Z5UrwsVtFd28efNUvvHGG1V2L/zKl5tePPHEEyq7v89NmzapnK8X+qXCvVjSvWlNpUr6vOStt94a9z1XrlypsnsRbCb07NlTZfemS2eccUbM13/yyScqp+MCt0Rx5hcAAADeoPkFAACAN2h+AQAA4A1mfh3luemHexML9yYXQDRVqui/ftOnT1d50KBBcd+D2c78NGrUKJVr1aql8uuvv67yI488kvGaoLkzljfddJPKNWrUULlRo0Yq5+rMrzub7M7wuj8j3ZtY9OnTR+W9e/emsbr8MG7cOJXr16+vcrybXkSbAS4uLlZ5586d5awucXfddZfKJ554Yszt16xZo/LPf/7ztNeUKM78AgAAwBs0vwAAAPAGzS8AAAC8Ycoz41ruDzMmex+WoG7duqm8fPnyuK9xZ3rdmV9fWGtNJt43F/eTdKhbt67KBQUFKrtznq5ly5ZFPNarVy+Vjxw5Us7qMidT+4lI/uwrLVq0UNmds3T96le/UnnatGlprykIFemY4s7wzpo1S+XOnTurvGfPHpVnz56t8sSJEyM+I9PzsgMGDIh47PHHH1fZXX/c3Tfdn3/ZmPHNt2NK7dq1VXbX7R48eHA2yym3oqIild11fPv16xfz+Uwoa1/hzC8AAAC8QfMLAAAAb9D8AgAAwBvezfwy45s+FWk+L1nuftKkSROVP/jgg7jv4c7TuWs3ums7ul577bWY7yci8vXXX8etI2j5Np+XCe6c5bBhw2Ju37dvX5VfeeWVtNcUhHw6puzevVvlevXqqVypkj73dPTo0Yj3cNcSdo87xug/Lvfnufu8u4avO5cc7T0WL16s8tVXX61yEOv45vsxxV3/tmfPniq3bds24jXt2rXLaE3RzJkzR2V3jv2ll17KZjlRMfMLAAAA79H8AgAAwBs0vwAAAPCGdzO/hYWFKrtrrUbjzvi6M8C+yqf5PNcdd9yh8v/8z/9k/DMXLFig8jXXXKPyd999l/EaMiHf5/PK47LLLlN57ty5Kruzmg8//LDK7jq/+SKfjinnnnuuyv/7v/+rsjtvG+1ncbIzvck+784Ui4jMnz9f5T/96U8R2wTN92NK8+bNIx5z57l79+6t8siRI5P6DHdt4eLi4oht3HnwH374IanPyAZmfgEAAOA9ml8AAAB4g+YXAAAA3qgSdAHZ1rVr16BLQAXgrrH77bffqlyrVq2I17jzde66nc8995zKDzzwgMpvvvmmykeOHEmsWFQ4xx9/vMruvuOu3+zOiyL3rV27VmV37fAuXbqofPnll0e8R7R1eJPxxhtvqDxv3jyVo838Ivf985//jPvY888/r/Ktt96a0ZoqGs78AgAAwBs0vwAAAPAGzS8AAAC84d3Mrzt3VZ7XsM5v/nPnb2vXrh1QJfDBgQMHVB40aJDK27dvz2Y5yILXX389ZgaQOZz5BQAAgDdofgEAAOANml8AAAB4g+YXAAAA3jDW2ux9mDHZ+7AyuBevFRQUqOze3EBEpLCwMIMVVVzWWhN/q+Tlwn6C9MnUfiLCvpJvOKYgERxTkKiy9hXO/AIAAMAbNL8AAADwBs0vAAAAvOHdzC/Sh/k8JIL5PCSKYwoSwTEFiWLmFwAAAN6j+QUAAIA3aH4BAADgDZpfAAAAeIPmFwAAAN6g+QUAAIA3aH4BAADgjayu8wsAAAAEiTO/AAAA8AbNLwAAALxB8wsAAABv0PwCAADAGzS/AAAA8AbNLwAAALxB8wsAAABv0PymyBgzwhhjE/j6WdC1InjGmFrGmEJjzHpjzHfGmG+MMW8bY243xlQNuj7kJmPMuNLHk6DrQe4wxvQ0xjxrjNlujPnBGHPAGLPVGPOUMaZr0PUhWAn2JyVfy4OuN1uqBF1AHjkqIntiPH8wW4UgNxljGonIChFpHH6oSESOF5H24a+rjDE9rLVfBVIgcpIxpoWIFARdB3KLMcaIyCMiMrLUwz+IiBWRJuGvYcaYP1prfx1AicgN/4rz/HEiUjf8/dsZriVncOY3fXZYaxvE+Hoj6AIRHGNMZRF5QUKN7xci0tNaW0NEqovIEBH5VkTOEZGngqoRuccYU0lEZohINRH5v4DLQW4ZIcca3/8nIs2ttSdYa6uLSEsRWRh+bowxZkAA9SEHxOlLGojIxFKbzwiqzmyj+QWyY4SI/DT8/UBr7VIREWvtUWvtM3Lsh1gfY0yPAOpDbholIh0l9D9FiwOuBbnlmvCvH4nIUGvthyVPWGu3iMggEdkafmhwlmtDxXFD+NeV4f3GCzS/QHZcG/51ubU22hm8OSKyLfz9NVGeh2eMMU1EZIKIfCkiYwIuB7nn1PCv71lrD7tPWmuLReTdcKyZtapQYRhjLhSRVuH41yBryTaaXyDDjDHVJXT2TkRkUbRtrLVWRF4Ox4uzURdy3qMiUkNEfm2tjXU9AfxUcla3rTEm4vodY8xxInJ2OK7JWlWoSErO+u4XkeeCLCTbaH7T5xRjzNrwFfwlV9s+aYzpFnRhCFwrOfZ3bUOM7Uqea2CMqRtjO+Q5Y8xNItJDRJZaax8Puh7kpEfCvzYTkaeNMc1KnghfJPmsiDQVkY9F5I/ZLw+5zBhTU46Nw8y21hYFWU+20fymT3URaScihyT059pERK4SkeXGmJnR/s8c3mhY6vudMbYr/VzDMrdCXjPGnCYiU0TkgOgr+YF/s9a+IKFxmEMicqWIfGiMKTLGFInIZhHpJqEG+Xxr7f7ACkWuGiLHxmG8GnkQoflNh89FZLyItBWRatbauhJqhDuKyNLwNtcJ/+fts1qlvo/1f9eln6tV5lbId9NFpLaIFFprt8bbGP6y1t4vIleIyO7wQyeEv0RCyyjWktC+BLhuDP/6nrV2baCVBIDmN0XW2sXW2kJr7fvW2oPhx45Ya1eJSC85ttzMrcaYnwRWKICcZ4wZLiJ9JXSh0tSAy0EOM8ZUN8Y8IyIvisinErpW4GQROSX8/UYRGS4ibxljzgqsUOQcY0xrEbkgHL076ytC85tR1tqjIjI2HCuJSL8Ay0Fwvi31ffUY25V+7tsyt0JeMsbUF5H7ReSIiNwU7Qp+oJQpEprZ/KeIdLHWLrHWfmmt3WutXSIiXcLPnSwi0wKsE7mn5KzvD+Lp2vI0vxlmrf1IRPaGY9Mga0FgPi/1/Wkxtiv93OdlboV8NVlE6onIX0RkszGmZukvEfn37a9LPc4tsT1kjKklIjeH40PW2gPuNuHHHgrHTuH/uYLnwseM4eE419c7itL8Apn3gYRufy0i0ibGdiXP7bLW7stsSchBTcK/3iKhM//u129LbVvy2L3ZLBA5o7mIlFxE/XGM7T4s9X2TMreCT/pL6F8DRDwdeRCh+c04Y8wZcmxH2xZrW+Sn8BIy/wjH3tG2McYYCc2Ii3AnLwCxHS31faMY2/2o1PeMUkHk2MjDRyLyWpCFBInmNwXhhiXe81PC8aiELkyAn2aFf+1ujLkgyvOD5NhYDOu6esha281aa8r6ktCqMiXbljw+OsCSEZzNEloKT0TkxjJuclFZjo1GfCUi3ty6FtEZY04XkZ+F48zwzZW8RPObmkbGmLeMMSONMU1LmmFjTCVjTAcJ3c1rQHjb6T7dNxsRZonIehExIjLXGNND5N/7yiAJ3c1LRGSRtfbVgGoEUAGE53lL/sm6nYi8YIz5afh4Uim8usPfReTC8Db3W2uPBFErcsr1Eur7DovI34ItJVjG48Y/ZcaYxqJHGQ5K6J+WaklojcUSj4nIzVy97bfw/rJcRBqHHyqS0IGoWji/IyI9fL0AAbEZYwpFpEAkdOY32GoQNGPMCSIyT/Qo1cHwr6V//jwtIlfT/PrNGFNJQrfEbiQiz1tr+wdcUqA485uaf4nIKBGZLSKbJHR/7DoiUiyhf5aaKSKdrLXX0/jCWvuJiJwlIndL6FbGVkL7yloJLYnXgcYXQCLCZ38vkdDI1EIR+UxC/7IkIrJDROaKyKXW2mE0vpDQuEPJfLi3F7qV4MwvAAAAvMGZXwAAAHiD5hcAAADeoPkFAACAN2h+AQAA4A2aXwAAAHgj4q4wmWSMYWmJPJKptUbZT/JLJtekZV/JLxxTkAiOKUhUWfsKZ34BAADgDZpfAAAAeIPmFwAAAN6g+QUAAIA3aH4BAADgDZpfAAAAeIPmFwAAAN6g+QUAAIA3aH4BAADgDZpfAAAAeIPmFwAAAN6g+QUAAIA3aH4BAADgDZpfAAAAeIPmFwAAAN6g+QUAAIA3aH4BAADgDZpfAAAAeIPmFwAAAN6g+QUAAIA3qgRdQK6pU6dOxGO33367yr169VK5ffv2SX2GMUZla21SrxcR2b17t8p9+/ZV+b333lP58OHDSX8GytapU6eIxy688EKV27Ztq/LQoUNjvqe7XyxcuFDl++67L+I1K1eujPmeAPLXmWeeqfIvf/lLlVu1aqVy165dVXaPOSKRP4+2b9+u8oQJE1Revny5yh9//HGMioHcwJlfAAAAeIPmFwAAAN6g+QUAAIA3THnmTcv9YcZk78MS5M7vPvfccxHb1KhRI1vlpE3v3r1VXrJkSdo/w1obOTCWBrmwn5x44okqDxs2TOUpU6ZEvKZ69eoZramoqCjisX79+qm8YsWKjNZQHpnaT0RyY1/JRX/4wx8iHrvrrrtU/s///E+VV69endGaEpHPx5TyaNOmjcq/+c1vVL7iiitUzvQxKJpvvvlG5YEDB6rszgSnA8cUJKqsfYUzvwAAAPAGzS8AAAC8QfMLAAAAb3i3zm+fPn1Ufuqpp1Quz3zvtm3bVH733XdjfkYi3NmuatWqqeyuIeuqX79+0p+JY7p06aLytGnTUn7PvXv3quzOWJ5wwgkq9+jRQ+Vo83xz585V2V1LePHixUnXidS46zNHm6WdNGlSWj/z5JNPVnn06NER22Tz+g4kb/DgwRGPPfHEEypXqRL7R/bBgwdV3rFjR8ztN27cGPHY2WefrXKjRo1ivkft2rVVvuSSS1TOxMwvInXr1i1mLigoSPtnjh8/XmX3mpNcvAalBGd+AQAA4A2aXwAAAHiD5hcAAADe8G7md+zYsSq780rRuPcqf/TRR1V257J27dpVzuqOmT9/vsruPdmXLVum8rx581R+4YUXUq7BJw888IDKQ4YMSfo93P/uN998s8rbt29XecOGDSoz3zZmAAAOCUlEQVQff/zxKk+YMEHlMWPGRHxmnTp1VHb3RXe/2bx5c8R7IDU33HCDyu7M45YtWzJew6BBg1SuiGuT+2bEiBEqT548OWKbeDO+L7/8ssruXOeaNWuSrqtx48Yquz//4tm6dWvSn4nYCgsLVc7E/G55uHXEq8udEXa3d593f9/pxJlfAAAAeIPmFwAAAN6g+QUAAIA3vJv5LY+nn35a5SlTpmT8M6tWraryr371K5XbtWunsjtn9e2332amsDzhzkRecMEFKterVy/p93zllVdi5sOHD8d8vbtG5+9+9zuV3RlBEZGTTjpJZXe91yZNmqjMzG/6DRw4UOXKlSur7K4tLiJyxx13pLWGPXv2pPX9kHlNmzZV2f27G417bYK7Hny8Y0wi3PVh43F/9jzzzDMp1+Ab9888HWsju2vsuvO08bZPZJ3gZPeVeDPB7jUqmcSZXwAAAHiD5hcAAADeoPkFAACAN5j5zVGHDh1S+brrrlN5//792Swn73Tv3l3l9u3bp/yeV1xxhcp33nmnyl988UVS7+fuAxdffHHENitXrlTZXSv4t7/9rcpLly5Vubi4OKmaEDnT6/6ZuxYtWpTJckQkcvY7Ee7+unr16nSVgwT8x3/8R9KvcY8hyc741qxZU+XOnTtHbPPggw8m9Z7btm1Ted++fUm93kfuTG+ys7PRpHuNXHcG2M3RPsOd2U3295WOP4dEceYXAAAA3qD5BQAAgDdofgEAAOANml8AAAB4w7sL3o4cORJ0CeXCBW7pFe3isWS8+uqrEY+5NzNI9762bt26iMdefPFFld0bLnTs2FFl9/f90ksvpak6f5x33nkquxdPutwLgjLhpptuirvN4sWLVT7xxBMzVQ4S0Ldv36Rf415g5O5bzz33XMzXuxfAjhs3LukaXO7NeRBfqhd2RbthRaoXuJWH+5mp3pwj3rE0nTjzCwAAAG/Q/AIAAMAbNL8AAADwhnczv1OnTlW5R48ecV9z0UUXqXzvvfeq/P3336deGLIqkf/usbz22msRjwUxT75s2TKV3ZlfpN+MGTNiPv/QQw+p/Mwzz2SynIS5s5lvvvlmQJVARGTkyJEqjxgxImKbSy+9VGX3hiru7Kd70xv3Z1cixwd3PykoKFB5x44dKv/jH/+I+57Q3BtGuDPA7n/XRG44EYRUb9YR7/eZSZz5BQAAgDdofgEAAOANml8AAAB4w7uZ3/Xr16v87rvvqnz22WdHvObCCy9Uef78+SqnumYsMu+MM85QOdk1TouLi1XeuHFjyjWlw4cffqjyd999p3LNmjVVvvPOO1Vmnd/kVa5cOebzr7/+usp169aN2Obw4cMqZ2Mdb2OMyrkyi+wr9+fIkiVLIrZx/xv17t1b5RYtWqi8Zs0alevUqaNytWrVVI52nYL78879GYnUZXM923SJto5wsjO+7u87yNllzvwCAADAGzS/AAAA8AbNLwAAALzh3czvzp07Vb7ssstUXrduXcRrTj75ZJU7deqk8syZM1UeO3asyvv27Uu6TqTXV199pfKhQ4eSev2BAwdUXrBgQco1pcOrr76q8p49e1R2Z35r1aqV8ZryjTtn2bBhw5jbP/vss3Hf84svvlB57dq1Kj///PMqb9q0SWV3hr1Zs2ZxP3PVqlUqFxUVxX0Nssed1xcRGTJkiMru2szuzG+DBg1ifsb777+vcp8+fSK22bVrV8z3gB/cGV93vedE5Or6xCKc+QUAAIBHaH4BAADgDZpfAAAAeMNYa7P3YcZk78PKqX379hGPzZgxQ+U2bdrEfI+lS5eqPHToUJXzZQbYWmvib5W8bOwnY8aMUfm+++6Lub27DutJJ52U9prSYdy4cSpPmDBBZXd29Kc//WnGa8rUfiKSnX3l008/VflHP/qRyhs2bFB59erVKn/yyScR7+nOcp511lkqu2sJu+tMV6miL9dw1/CNtm5wy5YtVc7F2c6KfEzJhq5du6q8bNmypF4/evRolR988MGUawpCRT+m5KJ0zPiOHz8+5nsGoax9hTO/AAAA8AbNLwAAALxB8wsAAABvMPObgFNPPVXlzz77LKnXb9++XWV33nThwoXlKyxgFXk+77TTTlN5yZIlKrvrZ1aUmd+BAweq7K45y8xv8s4991yVW7durfLjjz+e8me41xG4/13OP/98lS+44AKVO3TooLK7TrCIyOWXX55KiVlRkY8pmZDscSqejRs3quzOmlcUFf2Ykgu6deum8vLly5N+D3fd3u7du6dQUWYw8wsAAADv0fwCAADAGzS/AAAA8EaV+JvAXQ9z5MiRKk+fPj3m6xs1aqTy7NmzVY62Jqe7fuNVV10Vt04kbufOnSrv3r1bZXeWrlq1air36tUr4j1feeWVNFWHXLJ27dqYOR3ctYLd/PTTT6vszgi///77KrvHGOS+4cOHRzzmrpvauHFjld1rdrZt26Zy06ZNVa5Tp47K9evXj/hM91iI/JDqOr7ufK9Ibs74JoozvwAAAPAGzS8AAAC8QfMLAAAAb9D8AgAAwBtc8JYA96KCGTNmqLx3716V3Yuhhg0bpnL16tVVjnbRgXuzgkceeUTllStXxqgYyXIvMOzcubPKVatWVbl9+/YR71ERLng75ZRTVG7btq3K7733XjbLQTm5Fy6h4pk0aZLKv/71ryO2qVy5ssqrV69W2f3Z8uMf/1jl119/XWX3phnuzxmRyJ81qJhSvcDNvZgt2gVvFRlnfgEAAOANml8AAAB4g+YXAAAA3mDmtxzcGeAFCxbEzLfccovKQ4cOVXny5MkRn+HOZrmL3Lds2VLl77//PkbFiGfChAkqFxcXq3zPPfeofNddd0W8xxtvvKGyO2+XDXfffXfM5/ft26fypk2bMlkOMqR///5Bl4AkTZw4UeUxY8aoXKVK5I9jdwa/Y8eOMT9jxIgRSdW0cePGpLZH7urWrZvKzPjGxplfAAAAeIPmFwAAAN6g+QUAAIA38n7m111Tt3nz5ip/9dVXKm/fvj3jNbnzuw0aNIjY5r777lO5YcOGKvfr10/lOXPmpKk6Px05ckTlxx57TOUbbrhB5SZNmkS8x8KFC1V21+2cP3++yl9//XXSdbrcOcJmzZrF3N79fbqzzagY3GsCkHvq1q2r8uDBg1U+7rjjVP74448j3uPSSy+N+Rk1a9ZU2f254HLXpP/0009jbo/c5M73iogsX748qfdwZ3rzfcbXxZlfAAAAeIPmFwAAAN6g+QUAAIA38n7m95JLLlH5mWeeUXnXrl0q/+1vf4t4jyVLlqjszsbUqFFD5fPPPz+pGq+66qqktkfmufuFO3u3aNGiiNecfvrpKv/1r39VefTo0So/8MADKn/00Ucxa7rooosiHhs7dqzKlStXjvke06ZNi/k8KoaePXsm/ZqqVauq7B6nVq5cmVJN0Nz13KNdJ1BatL+be/bsUfmaa65R2V0r+Kyzzor5Ge+8847Kn3zyScztkZuSXcNXJLJvGT9+fJqqqZg48wsAAABv0PwCAADAGzS/AAAA8Ebez/yec845MZ9319gdN25cxDb//d//rfLatWtVPuGEE1Ru3bp1MiUmpKioSOXPPvss7Z+Bsm3evFnlP/7xjxHbTJ06VWVjjMpt2rRR+S9/+UuaqivbsmXLVJ43b17GPxOZ9+KLL6p87bXXxn3NbbfdpnKLFi1UZuY3veLN+Lr69u0b8dioUaNSes8NGzaofM899yT1euQGdw3faOv8xuPO+Pq2rq+LM78AAADwBs0vAAAAvEHzCwAAAG8Ya232PsyY7H1YWLVq1VTu1KmTyldeeaXKw4YNi3gPdx3fbDh8+LDKP//5z1VesGBBNsuJylpr4m+VvCD2k3Rw1+B05+tOO+20tH/mDz/8oPKqVatUdvdnd93QbMjUfiJScfeVVLnz4++//77Kc+bMifse+/fvV/kXv/hF6oWlKJ+OKXfccYfKkyZNSvtnuOuRv/XWWypPnjxZ5dWrV6e9hiD4dkwpT5/WvXt3lX2d8S1rX+HMLwAAALxB8wsAAABv0PwCAADAG3k/85ssd05GRKR3794qjx07VuUvv/xS5RkzZiT1mWvWrIl47NVXX1X566+/Tuo9syGf5vMyoWXLlipfeumlKt94440q/+QnP1F54cKFKrvzvCIi7733nspLlixJus5M820+LxuOO+44ld1Zz7Zt20a85tChQyrfcsstKj/22GNpqq788umYcvzxx6vs/txw/75fffXVEe/x1FNPqfzhhx+qPHPmTJV37tyZdJ0VUb4dU9x1ewsKCmI+nwh3nXlfMfMLAAAA79H8AgAAwBs0vwAAAPAGzS8AAAC8wQVvKLd8ujgFmZNvF6fkIvfCqKFDh0Zs89JLL6ncr1+/jNZUHhxTkIh8O6YUFhaq7F7wlghuahEdF7wBAADAezS/AAAA8AbNLwAAALzBzC/Kjfk8JCLf5vOQORxTkIh8O6a4N7FYvnx5zO3Hjx8f8Zg7N4wQZn4BAADgPZpfAAAAeIPmFwAAAN5g5hflxnweEpFv83nIHI4pSATHFCSKmV8AAAB4j+YXAAAA3qD5BQAAgDeyOvMLAAAABIkzvwAAAPAGzS8AAAC8QfMLAAAAb9D8AgAAwBs0vwAAAPAGzS8AAAC8QfMLAAAAb9D8AgAAwBs0vwAAAPAGzS8AAAC8QfMLAAAAb9D8AgAAwBs0vwAAAPAGzS8AAAC8QfMLAAAAb9D8AgAAwBs0vwAAAPAGzS8AAAC8QfMLAAAAb9D8AgAAwBs0vwAAAPAGzS8AAAC8QfMLAAAAb/x/fP5YWbzDvrQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x360 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (41580, 784) (41580, 10)\n",
      "Validation set (210, 784) (210, 10)\n",
      "Test set (210, 784) (210, 10)\n"
     ]
    }
   ],
   "source": [
    "train = 0.99\n",
    "train_size = int(X_train.shape[0]*train)\n",
    "valid_size = int(X_train.shape[0]*(1.0 - train)/2.0)\n",
    "test_size = int(X_train.shape[0]*(1.0 - train)/2.0)\n",
    "\n",
    "# print(\"train_size: %0.d\"%train_size)\n",
    "# print(\"valid_size: %0.d\"%valid_size)\n",
    "# print(\"test_size: %0.d\"%test_size)\n",
    "\n",
    "def shuffle_data(a, b):\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(b)\n",
    "    \n",
    "# Mix all the data\n",
    "shuffle_data(X_train, y_train)\n",
    "\n",
    "# Get Train Data\n",
    "start_t = 0\n",
    "end_t = train_size\n",
    "train_dataset = X_train[start_t:end_t,:]\n",
    "train_labels = y_train[start_t:end_t]\n",
    "\n",
    "# Get Validation Data\n",
    "start_t = train_size\n",
    "end_t = valid_size + train_size\n",
    "valid_dataset = X_train[start_t:end_t,:]\n",
    "valid_labels = y_train[start_t:end_t]\n",
    "\n",
    "# Get Test Data\n",
    "start_t = valid_size + train_size\n",
    "end_t = valid_size + train_size + test_size\n",
    "test_dataset = X_train[start_t:end_t,:]\n",
    "test_labels = y_train[start_t:end_t]\n",
    "\n",
    "print('Training:', train_dataset.shape, train_labels.shape)\n",
    "print('Validation:', valid_dataset.shape, valid_labels.shape)\n",
    "print('Testing:', test_dataset.shape, test_labels.shape)\n",
    "\n",
    "def randomize(dataset, labels):\n",
    "    permutation = np.random.permutation(labels.shape[0])\n",
    "    shuffled_dataset = dataset[permutation,:]\n",
    "    shuffled_labels = labels[permutation]\n",
    "    return shuffled_dataset, shuffled_labels\n",
    "\n",
    "train_dataset, train_labels = randomize(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = randomize(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = randomize(test_dataset, test_labels)\n",
    "\n",
    "# Check if they are still ok\n",
    "displayImages(train_dataset, train_labels)\n",
    "\n",
    "image_size = 28  # Pixel width and height.\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "    # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "    labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "    return dataset, labels\n",
    "\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">**TensorFlow**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    correct_prediction = np.argmax(predictions, 1) == np.argmax(labels, 1)\n",
    "    accuracy = (100.0 * np.sum(correct_prediction) / predictions.shape[0])\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create graph object: instantiate\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    '''INPUT DATA'''\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape = [None, image_size * image_size], name = 'x-input')\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape = [None, num_labels], name = 'y-input')\n",
    "    tf_valid_dataset = tf.placeholder(tf.float32, shape = [None, image_size * image_size], name = 'x-input')\n",
    "    #y_valid = tf.placeholder(tf.float32, shape = [None, num_labels], name = 'y-input')\n",
    "    tf_test_dataset = tf.placeholder(tf.float32, shape = [None, image_size * image_size], name = 'x-input')\n",
    "    #y_test = tf.placeholder(tf.float32, shape = [None, num_labels], name = 'y-input')\n",
    "    \n",
    "    # Variables    \n",
    "    # They are variables we want to update and optimize.\n",
    "    weights = tf.Variable(tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "    # Training computation.\n",
    "    logits = tf.matmul(tf_train_dataset, weights) + biases \n",
    "    # Original loss function\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf_train_labels,  logits=logits) )\n",
    "    \n",
    "    '''OPTIMIZER'''\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    '''PREDICTIONS'''\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With gradient descent training, even this much data is prohibitive.\n",
    "# Subset the training data for faster turnaround.\n",
    "\n",
    "# train_subset = 2000\n",
    "train_subset = train_dataset.shape[0];\n",
    "valid_subset = valid_dataset.shape[0]\n",
    "test_subset = test_dataset.shape[0]\n",
    "\n",
    "num_steps = 10000\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        offset = 0\n",
    "        batch_data = train_dataset[offset:train_subset,:]\n",
    "        batch_labels = train_labels[offset:train_subset, :]\n",
    "        \n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        l, predictions, _ = session.run([loss, train_prediction, optimizer], feed_dict = feed_dict)\n",
    "                \n",
    "        if (step % 500 == 0):\n",
    "            print('============================================')\n",
    "            print(\"Loss at step {}: {}\".format(step, l))\n",
    "            print(\"Training accuracy: {:.1f}%\".format(accuracy(predictions, train_labels[:train_subset, :])))\n",
    "            print(\"Validation accuracy: {:.1f}%\".format(accuracy(valid_prediction.eval({tf_valid_dataset: valid_dataset}), valid_labels)))\n",
    "    print('=================Finished!!=====================')\n",
    "    print(\"Test accuracy: {:.1f}%\".format(accuracy(test_prediction.eval({tf_test_dataset: test_dataset}), test_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regrresion with Sthocastic Gradiend Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    '''INPUT DATA'''\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape = [None, image_size * image_size], name = 'x-input')\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape = [None, num_labels], name = 'y-input')\n",
    "    tf_valid_dataset = tf.placeholder(tf.float32, shape = [None, image_size * image_size], name = 'x-input')\n",
    "    tf_test_dataset = tf.placeholder(tf.float32, shape = [None, image_size * image_size], name = 'x-input')\n",
    "    \n",
    "    # Variables    \n",
    "    # They are variables we want to update and optimize.\n",
    "    weights = tf.Variable(tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "    # Training computation.\n",
    "    logits = tf.matmul(tf_train_dataset, weights) + biases \n",
    "    # Original loss function\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf_train_labels,  logits=logits) )\n",
    "    \n",
    "    '''OPTIMIZER'''\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    '''PREDICTIONS'''\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_steps = 10001\n",
    "\n",
    "with tf.Session(graph = graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        \n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        l, predictions, _ = session.run([loss, train_prediction, optimizer], feed_dict = feed_dict)\n",
    "                \n",
    "        if (step % 5000 == 0):\n",
    "            print('============================================')\n",
    "            print(\"Minibatch loss at step {}: {}\".format(step, l))\n",
    "            print(\"Minibatch accuracy: {:.1f}%\".format(accuracy(predictions, batch_labels)))\n",
    "            print(\"Validation accuracy: {:.1f}%\".format(accuracy(valid_prediction.eval({tf_valid_dataset: valid_dataset}), valid_labels)))\n",
    "    print('=================Finished!!=====================')\n",
    "    print(\"Test accuracy: {:.1f}%\".format(accuracy(test_prediction.eval({tf_test_dataset: test_dataset}), test_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression with Sthocastic Gradiend Descent and 1-hide layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    '''INPUT DATA'''\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape = [None, image_size * image_size], name = 'x-input')\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape = [None, num_labels], name = 'y-input')\n",
    "    tf_valid_dataset = tf.placeholder(tf.float32, shape = [None, image_size * image_size], name = 'x-input')\n",
    "    tf_test_dataset = tf.placeholder(tf.float32, shape = [None, image_size * image_size], name = 'x-input')\n",
    "    \n",
    "    # Variables    \n",
    "    # They are variables we want to update and optimize.\n",
    "    weights_1 = tf.Variable(tf.truncated_normal([image_size * image_size, num_nodes]))\n",
    "    biases_1 = tf.Variable(tf.zeros([num_nodes]))\n",
    "    \n",
    "    weights_2 = tf.Variable(tf.truncated_normal([num_nodes, num_labels]))\n",
    "    biases_2 = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "    # Training computation.\n",
    "    logits_1 = tf.matmul(tf_train_dataset, weights_1) + biases_1 \n",
    "    \n",
    "    #Activation function\n",
    "    relu_layer = tf.nn.relu(logits_1, name = 'activation')\n",
    "    tf.summary.histogram('Activations', relu_layer)\n",
    "    \n",
    "    # Training computation.\n",
    "    logits_2 = tf.matmul(relu_layer, weights_2) + biases_2    \n",
    "    \n",
    "    # Original loss function\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf_train_labels,  logits=logits_2) )\n",
    "    \n",
    "    '''OPTIMIZER'''\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    '''PREDICTIONS'''\n",
    "    train_prediction = tf.nn.softmax(logits_2)\n",
    "    \n",
    "    '''Validation'''\n",
    "    logits_1 = tf.matmul(tf_valid_dataset, weights_1) + biases_1\n",
    "    relu_layer = tf.nn.relu(logits_1, name = 'activation')\n",
    "    logits_2 = tf.matmul(relu_layer, weights_2) + biases_2\n",
    "    valid_prediction = tf.nn.softmax(logits_2)\n",
    "\n",
    "    '''Test'''\n",
    "    logits_1 = tf.matmul(tf_test_dataset, weights_1) + biases_1\n",
    "    relu_layer= tf.nn.relu(logits_1, name = 'activation')\n",
    "    logits_2 = tf.matmul(relu_layer, weights_2) + biases_2\n",
    "    test_prediction = tf.nn.softmax(logits_2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 1024\n",
    "batch_size = 128\n",
    "\n",
    "num_steps = 10001\n",
    "\n",
    "with tf.Session(graph = graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        \n",
    "        feed_dict = {tf_train_dataset: batch_data, tf_train_labels: batch_labels}\n",
    "        l, predictions, _ = session.run([loss, train_prediction, optimizer], feed_dict = feed_dict)\n",
    "                \n",
    "        if (step % 5000 == 0):\n",
    "            print('============================================')\n",
    "            print(\"Minibatch loss at step {}: {}\".format(step, l))\n",
    "            print(\"Minibatch accuracy: {:.1f}%\".format(accuracy(predictions, batch_labels)))\n",
    "            print(\"Validation accuracy: {:.1f}%\".format(accuracy(valid_prediction.eval({tf_valid_dataset: valid_dataset}), valid_labels)))\n",
    "    print('=================Finished!!=====================')\n",
    "    print(\"Test accuracy: {:.1f}%\".format(accuracy(test_prediction.eval({tf_test_dataset: test_dataset}), test_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a good beta value to start with\n",
    "beta = 0.01\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    '''INPUT DATA'''\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape = [None, image_size * image_size], name = 'x-input')\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape = [None, num_labels], name = 'y-input')\n",
    "    tf_valid_dataset = tf.placeholder(tf.float32, shape = [None, image_size * image_size], name = 'x-input')\n",
    "    tf_test_dataset = tf.placeholder(tf.float32, shape = [None, image_size * image_size], name = 'x-input')\n",
    "    \n",
    "    # Variables    \n",
    "    # They are variables we want to update and optimize.\n",
    "    weights = tf.Variable(tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "    # Training computation.\n",
    "    logits = tf.matmul(tf_train_dataset, weights) + biases \n",
    "    # Original loss function\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf_train_labels,  logits=logits) )\n",
    "\n",
    "    # Loss function using L2 Regularization\n",
    "    regularizer = tf.nn.l2_loss(weights)\n",
    "    loss = tf.reduce_mean(loss + beta * regularizer)\n",
    "    \n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax( tf.matmul(tf_valid_dataset, weights) + biases )\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to expedite the process \n",
    "train_subset = 10000\n",
    "#train_subset = train_dataset.shape[0]\n",
    "valid_subset = valid_dataset.shape[0]\n",
    "test_subset = test_dataset.shape[0]\n",
    "\n",
    "num_steps = 5001\n",
    "\n",
    "with tf.Session(graph = graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        train_data = train_dataset[:train_subset, :]\n",
    "        train_labels = train_labels[:train_subset]\n",
    "        feed_dict = {tf_train_dataset: train_data, tf_train_labels: train_labels}\n",
    "\n",
    "        l, predictions, _ = session.run([loss, train_prediction, optimizer], feed_dict = feed_dict)\n",
    "                \n",
    "        if (step % 5000 == 0):\n",
    "            print('============================================')\n",
    "            print(\"Loss at step {}: {}\".format(step, l))\n",
    "            print(\"Training accuracy: {:.1f}%\".format(accuracy(predictions, train_labels[:train_subset, :])))\n",
    "            print(\"Validation accuracy: {:.1f}%\".format(accuracy(valid_prediction.eval({tf_valid_dataset: valid_dataset}), valid_labels)))\n",
    "    print('=================Finished!!=====================')\n",
    "    print(\"Test accuracy: {:.1f}%\".format(accuracy(test_prediction.eval({tf_test_dataset: test_dataset}), test_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network with L2 Regularization\n",
    "\n",
    "-  Hidden Layer using RELUs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a good beta value to start with\n",
    "num_nodes= 1024\n",
    "beta = 0.01\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    '''INPUT DATA'''\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape = [None, image_size * image_size], name = 'x-input')\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape = [None, num_labels], name = 'y-input')\n",
    "    tf_valid_dataset = tf.placeholder(tf.float32, shape = [None, image_size * image_size], name = 'x-input')\n",
    "    tf_test_dataset = tf.placeholder(tf.float32, shape = [None, image_size * image_size], name = 'x-input')\n",
    "    \n",
    "    # Variables    \n",
    "    # They are variables we want to update and optimize.\n",
    "    weights_1 = tf.Variable(tf.truncated_normal([image_size * image_size, num_nodes]))\n",
    "    biases_1 = tf.Variable(tf.zeros([num_nodes]))\n",
    "    \n",
    "    weights_2 = tf.Variable(tf.truncated_normal([num_nodes, num_labels]))\n",
    "    biases_2 = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "    # Training computation.\n",
    "    logits_1 = tf.matmul(tf_train_dataset, weights_1) + biases_1 \n",
    "    \n",
    "    #Activation function\n",
    "    relu_layer = tf.nn.relu(logits_1, name = 'activation')\n",
    "    \n",
    "    # Training computation.\n",
    "    logits_2 = tf.matmul(relu_layer, weights_2) + biases_2    \n",
    "    \n",
    "    # Original loss function\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf_train_labels,  logits=logits_2))\n",
    "    \n",
    "    # Loss function using L2 Regularization\n",
    "    regularizers = tf.nn.l2_loss(weights_1) + tf.nn.l2_loss(weights_2)\n",
    "    loss = tf.reduce_mean(loss + beta * regularizers)\n",
    "    \n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    '''PREDICTIONS'''\n",
    "    train_prediction = tf.nn.softmax(logits_2)\n",
    "    \n",
    "    '''Validation'''\n",
    "    logits_1 = tf.matmul(tf_valid_dataset, weights_1) + biases_1\n",
    "    relu_layer = tf.nn.relu(logits_1, name = 'activation')\n",
    "    logits_2 = tf.matmul(relu_layer, weights_2) + biases_2\n",
    "    valid_prediction = tf.nn.softmax(logits_2)\n",
    "\n",
    "    '''Test'''\n",
    "    logits_1 = tf.matmul(tf_test_dataset, weights_1) + biases_1\n",
    "    relu_layer= tf.nn.relu(logits_1, name = 'activation')\n",
    "    logits_2 = tf.matmul(relu_layer, weights_2) + biases_2\n",
    "    test_prediction = tf.nn.softmax(logits_2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "============================================\n",
      "Minibatch loss at step 0: 3343.325927734375\n",
      "Minibatch accuracy: 5.5%\n",
      "Validation accuracy: 23.0%\n",
      "============================================\n",
      "Minibatch loss at step 5000: 0.45578473806381226\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.7%\n",
      "============================================\n",
      "Minibatch loss at step 10000: 0.5341718196868896\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 93.1%\n",
      "=================Finished!!=====================\n",
      "Test accuracy: 91.4%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "num_steps = 10001\n",
    "\n",
    "with tf.Session(graph = graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        \n",
    "        feed_dict = {tf_train_dataset: batch_data, tf_train_labels: batch_labels}\n",
    "        l, predictions, _ = session.run([loss, train_prediction, optimizer], feed_dict = feed_dict)\n",
    "                \n",
    "        if (step % 5000 == 0):\n",
    "            print('============================================')\n",
    "            print(\"Minibatch loss at step {}: {}\".format(step, l))\n",
    "            print(\"Minibatch accuracy: {:.1f}%\".format(accuracy(predictions, batch_labels)))\n",
    "            print(\"Validation accuracy: {:.1f}%\".format(accuracy(valid_prediction.eval({tf_valid_dataset: valid_dataset}), valid_labels)))\n",
    "    print('=================Finished!!=====================')\n",
    "    print(\"Test accuracy: {:.1f}%\".format(accuracy(test_prediction.eval({tf_test_dataset: test_dataset}), test_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "Let's demonstrate an extreme case of overfitting. Restrict your training data to just a few batches. What happens?\n",
    "\n",
    "---\n",
    "#### Continuing from the Neural Network with L2 Regularization above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "============================================\n",
      "Minibatch loss at step 0: 3434.2236328125\n",
      "Minibatch accuracy: 4.7%\n",
      "Validation accuracy: 10.8%\n",
      "============================================\n",
      "Minibatch loss at step 500: 21.735700607299805\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 88.0%\n",
      "============================================\n",
      "Minibatch loss at step 1000: 0.4596632719039917\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 87.7%\n",
      "============================================\n",
      "Minibatch loss at step 1500: 0.300018846988678\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 87.8%\n",
      "============================================\n",
      "Minibatch loss at step 2000: 0.29781514406204224\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 87.4%\n",
      "============================================\n",
      "Minibatch loss at step 2500: 0.2949833571910858\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 87.8%\n",
      "============================================\n",
      "Minibatch loss at step 3000: 0.2930670976638794\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 87.4%\n",
      "=================Finished!!=====================\n",
      "Test accuracy: 86.8%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "train_dataset_2 = train_dataset[:500, :]\n",
    "train_labels_2 = train_labels[:500]\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels_2.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset_2[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels_2[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print('============================================')\n",
    "            print(\"Minibatch loss at step {}: {}\".format(step, l))\n",
    "            print(\"Minibatch accuracy: {:.1f}%\".format(accuracy(predictions, batch_labels)))\n",
    "            print(\"Validation accuracy: {:.1f}%\".format(accuracy(valid_prediction.eval({tf_valid_dataset: valid_dataset}), valid_labels)))\n",
    "    print('=================Finished!!=====================')\n",
    "    print(\"Test accuracy: {:.1f}%\".format(accuracy(test_prediction.eval({tf_test_dataset: test_dataset}), test_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Drop Out\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes= 1024\n",
    "beta = 0.01\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    '''INPUT DATA'''\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape = [None, image_size * image_size], name = 'x-input')\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape = [None, num_labels], name = 'y-input')\n",
    "    tf_valid_dataset = tf.placeholder(tf.float32, shape = [None, image_size * image_size], name = 'x-input')\n",
    "    tf_test_dataset = tf.placeholder(tf.float32, shape = [None, image_size * image_size], name = 'x-input')\n",
    "\n",
    "    # Variables.\n",
    "    weights_1 = tf.Variable(tf.truncated_normal([image_size * image_size, num_nodes]))\n",
    "    biases_1 = tf.Variable(tf.zeros([num_nodes]))\n",
    "    weights_2 = tf.Variable(tf.truncated_normal([num_nodes, num_labels]))\n",
    "    biases_2 = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "    # Training computation.\n",
    "    logits_1 = tf.matmul(tf_train_dataset, weights_1) + biases_1\n",
    "    relu_layer= tf.nn.relu(logits_1)\n",
    "    # Dropout on hidden layer: RELU layer\n",
    "    keep_prob = tf.placeholder(\"float\")\n",
    "    relu_layer_dropout = tf.nn.dropout(relu_layer, rate = 1.0 - keep_prob)\n",
    "    \n",
    "    logits_2 = tf.matmul(relu_layer_dropout, weights_2) + biases_2\n",
    "    # Normal loss function\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = tf_train_labels , logits = logits_2))\n",
    "    # Loss function with L2 Regularization with beta=0.01\n",
    "    regularizers = tf.nn.l2_loss(weights_1) + tf.nn.l2_loss(weights_2)\n",
    "    loss = tf.reduce_mean(loss + beta * regularizers)\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # Predictions for the training\n",
    "    train_prediction = tf.nn.softmax(logits_2)\n",
    "    \n",
    "    # Predictions for validation \n",
    "    logits_1 = tf.matmul(tf_valid_dataset, weights_1) + biases_1\n",
    "    relu_layer= tf.nn.relu(logits_1)\n",
    "    logits_2 = tf.matmul(relu_layer, weights_2) + biases_2\n",
    "    \n",
    "    valid_prediction = tf.nn.softmax(logits_2)\n",
    "    \n",
    "    # Predictions for test\n",
    "    logits_1 = tf.matmul(tf_test_dataset, weights_1) + biases_1\n",
    "    relu_layer= tf.nn.relu(logits_1)\n",
    "    logits_2 = tf.matmul(relu_layer, weights_2) + biases_2\n",
    "    \n",
    "    test_prediction =  tf.nn.softmax(logits_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "============================================\n",
      "Minibatch loss at step 0: 3498.41455078125\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 9.8%\n",
      "============================================\n",
      "Minibatch loss at step 500: 21.46979331970215\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 94.6%\n",
      "============================================\n",
      "Minibatch loss at step 1000: 0.8291898965835571\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 93.0%\n",
      "============================================\n",
      "Minibatch loss at step 1500: 0.5511454939842224\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.8%\n",
      "============================================\n",
      "Minibatch loss at step 2000: 0.541413426399231\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 93.6%\n",
      "============================================\n",
      "Minibatch loss at step 2500: 0.6179152727127075\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 94.0%\n",
      "============================================\n",
      "Minibatch loss at step 3000: 0.6477959156036377\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.6%\n",
      "=================Finished!!=====================\n",
      "Test accuracy: 90.8%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "batch_size = 128\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        feed_dict = {tf_train_dataset: batch_data, tf_train_labels: batch_labels, keep_prob : 0.5}\n",
    "        \n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "\n",
    "        if (step % 500 == 0):\n",
    "            print('============================================')\n",
    "            print(\"Minibatch loss at step {}: {}\".format(step, l))\n",
    "            print(\"Minibatch accuracy: {:.1f}%\".format(accuracy(predictions, batch_labels)))\n",
    "            print(\"Validation accuracy: {:.1f}%\".format(accuracy(valid_prediction.eval({tf_valid_dataset: valid_dataset}), valid_labels)))\n",
    "    print('=================Finished!!=====================')\n",
    "    print(\"Test accuracy: {:.1f}%\".format(accuracy(test_prediction.eval({tf_test_dataset: test_dataset}), test_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "Multiple layers.\n",
    "---------\n",
    "\n",
    "#### Model\n",
    "\n",
    "- 5 hidden layers NN\n",
    "  -  RELUs\n",
    "  -  Number of nodes decrease by 50% with each hidden layer that is deeper in the neural net\n",
    "-  Overfitting measures\n",
    "  -  L2 Regularization\n",
    "    -  Learning rate (beta) with exponential decay\n",
    "  -  Dropout\n",
    "\n",
    "-  10,000 steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "beta = 0.001\n",
    "\n",
    "hidden_nodes_1 = 1024\n",
    "hidden_nodes_2 = int(hidden_nodes_1 * 0.5)\n",
    "hidden_nodes_3 = int(hidden_nodes_1 * np.power(0.5, 2))\n",
    "hidden_nodes_4 = int(hidden_nodes_1 * np.power(0.5, 3))\n",
    "hidden_nodes_5 = int(hidden_nodes_1 * np.power(0.5, 4))\n",
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    '''INPUT DATA'''\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape = [None, image_size * image_size], name = 'x-input')\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape = [None, num_labels], name = 'y-input')\n",
    "    tf_valid_dataset = tf.placeholder(tf.float32, shape = [None, image_size * image_size], name = 'x-input')\n",
    "    tf_test_dataset = tf.placeholder(tf.float32, shape = [None, image_size * image_size], name = 'x-input')\n",
    "    \n",
    "    '''Variables'''\n",
    "    # Hidden RELU layer 1\n",
    "    weights_1 = tf.Variable(tf.truncated_normal([image_size * image_size, hidden_nodes_1], stddev=math.sqrt(2.0/(image_size*image_size))))\n",
    "    biases_1 = tf.Variable(tf.zeros([hidden_nodes_1]))\n",
    "\n",
    "    # Hidden RELU layer 2\n",
    "    weights_2 = tf.Variable(tf.truncated_normal([hidden_nodes_1, hidden_nodes_2], stddev=math.sqrt(2.0/hidden_nodes_1)))\n",
    "    biases_2 = tf.Variable(tf.zeros([hidden_nodes_2]))\n",
    "    \n",
    "    # Hidden RELU layer 3\n",
    "    weights_3 = tf.Variable(tf.truncated_normal([hidden_nodes_2, hidden_nodes_3], stddev=math.sqrt(2.0/hidden_nodes_2)))\n",
    "    biases_3 = tf.Variable(tf.zeros([hidden_nodes_3]))\n",
    "    \n",
    "    # Hidden RELU layer 4\n",
    "    weights_4 = tf.Variable(tf.truncated_normal([hidden_nodes_3, hidden_nodes_4], stddev=math.sqrt(2.0/hidden_nodes_3)))\n",
    "    biases_4 = tf.Variable(tf.zeros([hidden_nodes_4]))\n",
    "    \n",
    "    # Hidden RELU layer 5\n",
    "    weights_5 = tf.Variable(tf.truncated_normal([hidden_nodes_4, hidden_nodes_5], stddev=math.sqrt(2.0/hidden_nodes_4)))\n",
    "    biases_5 = tf.Variable(tf.zeros([hidden_nodes_5]))\n",
    "    \n",
    "    # Output layer\n",
    "    weights_6 = tf.Variable(tf.truncated_normal([hidden_nodes_5, num_labels], stddev=math.sqrt(2.0/hidden_nodes_5)))\n",
    "    biases_6 = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "    '''Training computation'''\n",
    "    # Hidden RELU layer 1\n",
    "    logits_1 = tf.matmul(tf_train_dataset, weights_1) + biases_1\n",
    "    hidden_layer_1 = tf.nn.relu(logits_1)\n",
    "    # Dropout on hidden layer: RELU layer\n",
    "    keep_prob = tf.placeholder(\"float\")\n",
    "    hidden_layer_1_dropout = tf.nn.dropout(hidden_layer_1, keep_prob)\n",
    "    \n",
    "    # Hidden RELU layer 2\n",
    "    logits_2 = tf.matmul(hidden_layer_1_dropout, weights_2) + biases_2\n",
    "    hidden_layer_2 = tf.nn.relu(logits_2)\n",
    "    # Dropout on hidden layer: RELU layer\n",
    "    hidden_layer_2_dropout = tf.nn.dropout(hidden_layer_2, keep_prob)\n",
    "    \n",
    "    # Hidden RELU layer 3\n",
    "    logits_3 = tf.matmul(hidden_layer_2_dropout, weights_3) + biases_3\n",
    "    hidden_layer_3 = tf.nn.relu(logits_3)\n",
    "    # Dropout on hidden layer: RELU layer\n",
    "    hidden_layer_3_dropout = tf.nn.dropout(hidden_layer_3, keep_prob)\n",
    "    \n",
    "    # Hidden RELU layer 4\n",
    "    logits_4 = tf.matmul(hidden_layer_3_dropout, weights_4) + biases_4\n",
    "    hidden_layer_4 = tf.nn.relu(logits_4)\n",
    "    # Dropout on hidden layer: RELU layer\n",
    "\n",
    "    hidden_layer_4_dropout = tf.nn.dropout(hidden_layer_4, keep_prob)\n",
    "    \n",
    "    # Hidden RELU layer 5\n",
    "    logits_5 = tf.matmul(hidden_layer_4_dropout, weights_5) + biases_5\n",
    "    hidden_layer_5 = tf.nn.relu(logits_5)\n",
    "    # Dropout on hidden layer: RELU layer\n",
    "    hidden_layer_5_dropout = tf.nn.dropout(hidden_layer_5, keep_prob)\n",
    "    \n",
    "    # Output layer\n",
    "    logits_6 = tf.matmul(hidden_layer_5_dropout, weights_6) + biases_6 \n",
    "    \n",
    "    # Normal loss function\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = tf_train_labels, logits = logits_6))\n",
    "    # Loss function with L2 Regularization with decaying learning rate beta=0.5\n",
    "    regularizers = tf.nn.l2_loss(weights_1) + tf.nn.l2_loss(weights_2) + \\\n",
    "                   tf.nn.l2_loss(weights_3) + tf.nn.l2_loss(weights_4) + \\\n",
    "                   tf.nn.l2_loss(weights_5) + tf.nn.l2_loss(weights_6)\n",
    "    loss = tf.reduce_mean(loss + beta * regularizers)\n",
    "    \n",
    "    '''Optimizer'''\n",
    "    # Decaying learning rate\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    start_learning_rate = 0.5\n",
    "    learning_rate = tf.train.exponential_decay(start_learning_rate, global_step, 100000, 0.96, staircase=True)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    # Predictions for the training\n",
    "    train_prediction = tf.nn.softmax(logits_6)\n",
    "    \n",
    "    # Predictions for validation \n",
    "    valid_logits_1 = tf.matmul(tf_valid_dataset, weights_1) + biases_1\n",
    "    valid_relu_1 = tf.nn.relu(valid_logits_1)\n",
    "    \n",
    "    valid_logits_2 = tf.matmul(valid_relu_1, weights_2) + biases_2\n",
    "    valid_relu_2 = tf.nn.relu(valid_logits_2)\n",
    "    \n",
    "    valid_logits_3 = tf.matmul(valid_relu_2, weights_3) + biases_3\n",
    "    valid_relu_3 = tf.nn.relu(valid_logits_3)\n",
    "    \n",
    "    valid_logits_4 = tf.matmul(valid_relu_3, weights_4) + biases_4\n",
    "    valid_relu_4 = tf.nn.relu(valid_logits_4)\n",
    "    \n",
    "    valid_logits_5 = tf.matmul(valid_relu_4, weights_5) + biases_5\n",
    "    valid_relu_5 = tf.nn.relu(valid_logits_5)\n",
    "    \n",
    "    valid_logits_6 = tf.matmul(valid_relu_5, weights_6) + biases_6\n",
    "    \n",
    "    valid_prediction = tf.nn.softmax(valid_logits_6)\n",
    "    \n",
    "    # Predictions for test\n",
    "    test_logits_1 = tf.matmul(tf_test_dataset, weights_1) + biases_1\n",
    "    test_relu_1 = tf.nn.relu(test_logits_1)\n",
    "    \n",
    "    test_logits_2 = tf.matmul(test_relu_1, weights_2) + biases_2\n",
    "    test_relu_2 = tf.nn.relu(test_logits_2)\n",
    "    \n",
    "    test_logits_3 = tf.matmul(test_relu_2, weights_3) + biases_3\n",
    "    test_relu_3 = tf.nn.relu(test_logits_3)\n",
    "    \n",
    "    test_logits_4 = tf.matmul(test_relu_3, weights_4) + biases_4\n",
    "    test_relu_4 = tf.nn.relu(test_logits_4)\n",
    "    \n",
    "    test_logits_5 = tf.matmul(test_relu_4, weights_5) + biases_5\n",
    "    test_relu_5 = tf.nn.relu(test_logits_5)\n",
    "    \n",
    "    test_logits_6 = tf.matmul(test_relu_5, weights_6) + biases_6\n",
    "    \n",
    "    test_prediction = tf.nn.softmax(test_logits_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "============================================\n",
      "Minibatch loss at step 0: 4.266349792480469\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 16.5%\n",
      "============================================\n",
      "Minibatch loss at step 500: 1.5100842714309692\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 92.8%\n",
      "============================================\n",
      "Minibatch loss at step 1000: 1.2176426649093628\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 94.7%\n",
      "============================================\n",
      "Minibatch loss at step 1500: 0.8158614039421082\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 96.3%\n",
      "============================================\n",
      "Minibatch loss at step 2000: 0.7730122208595276\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 96.5%\n",
      "============================================\n",
      "Minibatch loss at step 2500: 0.724498450756073\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 94.0%\n",
      "============================================\n",
      "Minibatch loss at step 3000: 0.7107023000717163\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 95.3%\n",
      "============================================\n",
      "Minibatch loss at step 3500: 0.7920072078704834\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 96.8%\n",
      "============================================\n",
      "Minibatch loss at step 4000: 0.44705355167388916\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 96.5%\n",
      "============================================\n",
      "Minibatch loss at step 4500: 0.6300328969955444\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 96.6%\n",
      "============================================\n",
      "Minibatch loss at step 5000: 0.4066828191280365\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 96.7%\n",
      "============================================\n",
      "Minibatch loss at step 5500: 0.4119933843612671\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 96.5%\n",
      "============================================\n",
      "Minibatch loss at step 6000: 0.6006022691726685\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 94.3%\n",
      "============================================\n",
      "Minibatch loss at step 6500: 0.6402585506439209\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 96.5%\n",
      "============================================\n",
      "Minibatch loss at step 7000: 0.45595479011535645\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 96.9%\n",
      "============================================\n",
      "Minibatch loss at step 7500: 0.4372461438179016\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 97.3%\n",
      "============================================\n",
      "Minibatch loss at step 8000: 0.4712173640727997\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 96.5%\n",
      "============================================\n",
      "Minibatch loss at step 8500: 0.397516131401062\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 96.4%\n",
      "============================================\n",
      "Minibatch loss at step 9000: 0.5008581280708313\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 96.2%\n",
      "============================================\n",
      "Minibatch loss at step 9500: 0.591705322265625\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 96.0%\n",
      "=================Finished!!=====================\n",
      "Test accuracy: 97.1%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_steps = 10000\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, keep_prob : 0.5}\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "                \n",
    "        if (step % 500 == 0):\n",
    "            print('============================================')\n",
    "            print(\"Minibatch loss at step {}: {}\".format(step, l))\n",
    "            print(\"Minibatch accuracy: {:.1f}%\".format(accuracy(predictions, batch_labels)))\n",
    "            print(\"Validation accuracy: {:.1f}%\".format(accuracy(valid_prediction.eval({tf_valid_dataset: valid_dataset}), valid_labels)))\n",
    "    print('=================Finished!!=====================')\n",
    "    print(\"Test accuracy: {:.1f}%\".format(accuracy(test_prediction.eval({tf_test_dataset: test_dataset}), test_labels)))\n",
    "    \n",
    "    # Predict test Data\n",
    "    pred_labels = test_prediction.eval({tf_test_dataset: X_test_public})\n",
    "    pred_labels = np.argmax(pred_labels, 1)\n",
    "    displayImages(test_dataset, pred_labels)\n",
    "    \n",
    "    # Save in CSV\n",
    "    save_submission(\"simplemnist_tf_result.csv\", X_test_public, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "============================================\n",
      "Minibatch loss at step 0: 200.64515686035156\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 27.6%\n",
      "============================================\n",
      "Minibatch loss at step 5000: 0.7543364763259888\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 96.7%\n",
      "============================================\n",
      "Minibatch loss at step 10000: 0.18009300529956818\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 97.6%\n",
      "=================Finished!!=====================\n",
      "Test accuracy: 97.1%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is a good beta value to start with\n",
    "num_nodes = 256 # number of neurons in the hidden layer\n",
    "beta = 0.001\n",
    "\n",
    "eta = 5e-1 #Learning Rate\n",
    "alpha = 1e-6 # regularization\n",
    "gamma = 0.99 # RMSprop\n",
    "eps = 1e-3 # RMSprop\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    '''INPUT DATA'''\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape = [None, image_size * image_size], name = 'x-input')\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape = [None, num_labels], name = 'y-input')\n",
    "    tf_valid_dataset = tf.placeholder(tf.float32, shape = [None, image_size * image_size], name = 'x-input')\n",
    "    tf_test_dataset = tf.placeholder(tf.float32, shape = [None, image_size * image_size], name = 'x-input')\n",
    "    \n",
    "    # Variables    \n",
    "    # They are variables we want to update and optimize.\n",
    "    weights_1 = tf.Variable(tf.truncated_normal([image_size * image_size, num_nodes]))\n",
    "    #biases_1 = tf.Variable(tf.zeros([num_nodes]))\n",
    "    biases_1 = tf.Variable(tf.constant(1.0, shape=[num_nodes]))\n",
    "    \n",
    "    weights_2 = tf.Variable(tf.truncated_normal([num_nodes, num_labels]))\n",
    "    #biases_2 = tf.Variable(tf.zeros([num_labels]))\n",
    "    biases_2 = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "    \n",
    "    # Training computation.\n",
    "    logits_1 = tf.matmul(tf_train_dataset, weights_1) + biases_1 \n",
    "    \n",
    "    #Activation function\n",
    "    relu_layer = tf.nn.relu(logits_1, name = 'activation')\n",
    "    \n",
    "    # Training computation.\n",
    "    logits_2 = tf.matmul(relu_layer, weights_2) + biases_2    \n",
    "    \n",
    "    # Original loss function\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf_train_labels,  logits=logits_2))\n",
    "    \n",
    "    # Loss function using L2 Regularization\n",
    "    regularizers = tf.nn.l2_loss(weights_1) + tf.nn.l2_loss(weights_2)\n",
    "    loss = tf.reduce_mean(loss + beta * regularizers)\n",
    "    \n",
    "    # Optimizer.\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    start_learning_rate = 0.5\n",
    "    learning_rate = tf.train.exponential_decay(start_learning_rate, global_step, 100000, 0.96, staircase=True)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    '''PREDICTIONS'''\n",
    "    train_prediction = tf.nn.softmax(logits_2)\n",
    "    \n",
    "    '''Validation'''\n",
    "    logits_1 = tf.matmul(tf_valid_dataset, weights_1) + biases_1\n",
    "    relu_layer = tf.nn.relu(logits_1, name = 'activation')\n",
    "    logits_2 = tf.matmul(relu_layer, weights_2) + biases_2\n",
    "    valid_prediction = tf.nn.softmax(logits_2)\n",
    "\n",
    "    '''Test'''\n",
    "    logits_1 = tf.matmul(tf_test_dataset, weights_1) + biases_1\n",
    "    relu_layer= tf.nn.relu(logits_1, name = 'activation')\n",
    "    logits_2 = tf.matmul(relu_layer, weights_2) + biases_2\n",
    "    test_prediction = tf.nn.softmax(logits_2) \n",
    "    \n",
    "batch_size = 128\n",
    "num_steps = 10001  # number of iterations of gradient descent\n",
    "\n",
    "with tf.Session(graph = graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        \n",
    "        feed_dict = {tf_train_dataset: batch_data, tf_train_labels: batch_labels}\n",
    "        l, predictions, _ = session.run([loss, train_prediction, optimizer], feed_dict = feed_dict)\n",
    "                \n",
    "        if (step % 5000 == 0):\n",
    "            print('============================================')\n",
    "            print(\"Minibatch loss at step {}: {}\".format(step, l))\n",
    "            print(\"Minibatch accuracy: {:.1f}%\".format(accuracy(predictions, batch_labels)))\n",
    "            print(\"Validation accuracy: {:.1f}%\".format(accuracy(valid_prediction.eval({tf_valid_dataset: valid_dataset}), valid_labels)))\n",
    "    print('=================Finished!!=====================')\n",
    "    print(\"Test accuracy: {:.1f}%\".format(accuracy(test_prediction.eval({tf_test_dataset: test_dataset}), test_labels)))\n",
    "    \n",
    "    # Predict test Data\n",
    "    pred_labels = test_prediction.eval({tf_test_dataset: X_test_public})\n",
    "    pred_labels = np.argmax(pred_labels, 1)\n",
    "    displayImages(X_test_public, pred_labels)\n",
    "    \n",
    "    # Save in CSV\n",
    "    save_submission(\"simplemnist_tf_result.csv\", X_test_public, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
